{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-03-09T09:29:28.897419Z",
     "iopub.status.busy": "2022-03-09T09:29:28.896887Z",
     "iopub.status.idle": "2022-03-09T09:29:28.948042Z",
     "shell.execute_reply": "2022-03-09T09:29:28.947243Z",
     "shell.execute_reply.started": "2022-03-09T09:29:28.897322Z"
    },
    "papermill": {
     "duration": 0.230891,
     "end_time": "2021-03-08T07:57:06.335029",
     "exception": false,
     "start_time": "2021-03-08T07:57:06.104138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "\n",
    "import random\n",
    "import io # Input/Output Module\n",
    "import os # OS interfaces\n",
    "import cv2 # OpenCV package\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from urllib import request # module for opening HTTP requests\n",
    "from matplotlib import pyplot as plt # Plotting library\n",
    "\n",
    "import copy\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils.fixes import loguniform\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# For Data Augmentation\n",
    "from torchvision import transforms as tr\n",
    "from torchvision.transforms import Compose\n",
    "from PIL import Image\n",
    "\n",
    "# For VGG Classifier\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "# from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022868,
     "end_time": "2021-03-08T07:57:06.382109",
     "exception": false,
     "start_time": "2021-03-08T07:57:06.359241",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"width:100%; height:140px\">\n",
    "    <img src=\"https://www.kuleuven.be/internationaal/thinktank/fotos-en-logos/ku-leuven-logo.png/image_preview\" width = 300px, heigh = auto align=left>\n",
    "</div>\n",
    "\n",
    "\n",
    "KUL H02A5a Computer Vision: Group Assignment 1\n",
    "---------------------------------------------------------------\n",
    "Student numbers: <span style=\"color:red\">r0876133, r0876755, r3, r4, r5</span>.\n",
    "\n",
    "The goal of this assignment is to explore more advanced techniques for constructing features that better describe objects of interest and to perform face recognition using these features. This assignment will be delivered in groups of 5 (either composed by you or randomly assigned by your TA's).\n",
    "\n",
    "In this assignment you are a group of computer vision experts that have been invited to ECCV 2021 to do a tutorial about  \"Feature representations, then and now\". To prepare the tutorial you are asked to participate in a kaggle competition and to release a notebook that can be easily studied by the tutorial participants. Your target audience is: (master) students who want to get a first hands-on introduction to the techniques that you apply.\n",
    "\n",
    "---------------------------------------------------------------\n",
    "This notebook is structured as follows:\n",
    "\n",
    "0. Data loading & Preprocessing\n",
    "1. Feature Representations\n",
    "2. Evaluation Metrics \n",
    "3. Classifiers\n",
    "4. Experiments\n",
    "5. Publishing best results\n",
    "6. Discussion\n",
    "\n",
    "Make sure that your notebook is **self-contained** and **fully documented**. Walk us through all steps of your code. Treat your notebook as a tutorial for students who need to get a first hands-on introduction to the techniques that you apply. Provide strong arguments for the design choices that you made and what insights you got from your experiments. Make use of the *Group assignment* forum/discussion board on Toledo if you have any questions.\n",
    "\n",
    "Fill in your student numbers above and get to it! Good luck! \n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>NOTE:</b> This notebook is just a example/template, feel free to adjust in any way you please! Just keep things organised and document accordingly!\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>NOTE:</b> Clearly indicate the improvements that you make!!! You can for instance use titles like: <i>3.1. Improvement: Non-linear SVM with RBF Kernel.<i>\n",
    "</div>\n",
    "    \n",
    "---------------------------------------------------------------\n",
    "# 0. Data loading & Preprocessing\n",
    "\n",
    "## 0.1. Loading data\n",
    "The training set is many times smaller than the test set and this might strike you as odd, however, this is close to a real world scenario where your system might be put through daily use! In this session we will try to do the best we can with the data that we've got! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-09T09:29:28.954193Z",
     "iopub.status.busy": "2022-03-09T09:29:28.953352Z",
     "iopub.status.idle": "2022-03-09T09:29:32.840002Z",
     "shell.execute_reply": "2022-03-09T09:29:32.839124Z",
     "shell.execute_reply.started": "2022-03-09T09:29:28.954147Z"
    },
    "papermill": {
     "duration": 37.543619,
     "end_time": "2021-03-08T07:57:43.9495",
     "exception": false,
     "start_time": "2021-03-08T07:57:06.405881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The training set contains 80 examples, the test set contains 1816 examples.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "\n",
    "train = pd.read_csv(\n",
    "    './kaggle/input/kul-h02a5a-computer-vision-ga1-2022/train_set.csv', index_col = 0)\n",
    "train.index = train.index.rename('id')\n",
    "\n",
    "test = pd.read_csv(\n",
    "    './kaggle/input/kul-h02a5a-computer-vision-ga1-2022/test_set.csv', index_col = 0)\n",
    "test.index = test.index.rename('id')\n",
    "\n",
    "# read the images as numpy arrays and store in \"img\" column\n",
    "train['img'] = [cv2.cvtColor(np.load('./kaggle/input/kul-h02a5a-computer-vision-ga1-2022/train/train_{}.npy'.format(index), allow_pickle=False), cv2.COLOR_BGR2RGB) \n",
    "                for index, row in train.iterrows()]\n",
    "\n",
    "test['img'] = [cv2.cvtColor(np.load('./kaggle/input/kul-h02a5a-computer-vision-ga1-2022/test/test_{}.npy'.format(index), allow_pickle=False), cv2.COLOR_BGR2RGB) \n",
    "                for index, row in test.iterrows()]\n",
    "  \n",
    "\n",
    "train_size, test_size = len(train),len(test)\n",
    "\n",
    "\"The training set contains {} examples, the test set contains {} examples.\".format(train_size, test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023377,
     "end_time": "2021-03-08T07:57:43.997466",
     "exception": false,
     "start_time": "2021-03-08T07:57:43.974089",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "*Note: this dataset is a subset of the* [*VGG face dataset*](https://www.robots.ox.ac.uk/~vgg/data/vgg_face/).\n",
    "\n",
    "## 0.2. A first look\n",
    "Let's have a look at the data columns and class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-09T09:29:32.841625Z",
     "iopub.status.busy": "2022-03-09T09:29:32.841363Z"
    },
    "papermill": {
     "duration": 3.315629,
     "end_time": "2021-03-08T07:57:47.336913",
     "exception": false,
     "start_time": "2021-03-08T07:57:44.021284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The training set contains an identifier, name, image information and class label\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 3.283501,
     "end_time": "2021-03-08T07:57:50.644778",
     "exception": false,
     "start_time": "2021-03-08T07:57:47.361277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The test set only contains an identifier and corresponding image information.\n",
    "\n",
    "test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.046628,
     "end_time": "2021-03-08T07:57:50.716317",
     "exception": false,
     "start_time": "2021-03-08T07:57:50.669689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The class distribution in the training set:\n",
    "train.groupby('name').agg({'img':'count', 'class': 'max'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025108,
     "end_time": "2021-03-08T07:57:50.766719",
     "exception": false,
     "start_time": "2021-03-08T07:57:50.741611",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Note that **Jesse is assigned the classification label 1**, and **Mila is assigned the classification label 2**. The dataset also contains 20 images of **look alikes (assigned classification label 0)** and the raw images. \n",
    "\n",
    "## 0.3. Preprocess data\n",
    "### 0.3.1 Example: HAAR face detector\n",
    "In this example we use the [HAAR feature based cascade classifiers](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_objdetect/py_face_detection/py_face_detection.html) to detect faces, then the faces are resized so that they all have the same shape. If there are multiple faces in an image, we only take the first one. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>NOTE:</b> You can write temporary files to <code>/kaggle/temp/</code> or <code>../../tmp</code>, but they won't be saved outside of the current session\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.042776,
     "end_time": "2021-03-08T07:57:50.834913",
     "exception": false,
     "start_time": "2021-03-08T07:57:50.792137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HAARPreprocessor():\n",
    "    \"\"\"Preprocessing pipeline built around HAAR feature based cascade classifiers. \"\"\"\n",
    "    \n",
    "    def __init__(self, path, face_size):\n",
    "        self.face_size = face_size\n",
    "        file_path = os.path.join(path, \"haarcascade_frontalface_default.xml\")\n",
    "        if not os.path.exists(file_path): \n",
    "            if not os.path.exists(path):\n",
    "                os.mkdir(path)\n",
    "            self.download_model(file_path)\n",
    "        \n",
    "        self.classifier = cv2.CascadeClassifier(file_path)\n",
    "  \n",
    "    def download_model(self, path):\n",
    "        url = \"https://raw.githubusercontent.com/opencv/opencv/master/data/\"\\\n",
    "            \"haarcascades/haarcascade_frontalface_default.xml\"\n",
    "        \n",
    "        with request.urlopen(url) as r, open(path, 'wb') as f:\n",
    "            f.write(r.read())\n",
    "            \n",
    "    def detect_faces(self, img):\n",
    "        \"\"\"Detect all faces in an image.\"\"\"        \n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        norm_img = np.zeros((FACE_SIZE[0], FACE_SIZE[1]))\n",
    "        img_gray = cv2.normalize(img_gray, norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "        return self.classifier.detectMultiScale(\n",
    "            img_gray,\n",
    "            scaleFactor=1.25,\n",
    "            minNeighbors=4,\n",
    "            minSize=(40, 40),\n",
    "            flags=cv2.CASCADE_SCALE_IMAGE  \n",
    "        )\n",
    "        \n",
    "    def extract_faces(self, img):\n",
    "        \"\"\"Returns all faces (cropped) in an image.\"\"\"\n",
    "        \n",
    "        faces = self.detect_faces(img)\n",
    "\n",
    "        return [img[y:y+h, x:x+w] for (x, y, w, h) in faces]\n",
    "    \n",
    "    def preprocess(self, data_row):\n",
    "        faces = self.extract_faces(data_row['img'])\n",
    "        \n",
    "        # if no faces were found, return None\n",
    "        if len(faces) == 0:\n",
    "            nan_img = np.empty(self.face_size + (3,))\n",
    "            nan_img[:] = np.nan\n",
    "            return nan_img\n",
    "        # only return the first face\n",
    "        return cv2.resize(faces[0], self.face_size, interpolation = cv2.INTER_AREA)\n",
    "            \n",
    "    def __call__(self, data):\n",
    "        return np.stack([self.preprocess(row) for _, row in data.iterrows()]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DNNPreprocessor improves the HAARPreprocessor. Probably best performing face detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNNPreprocessor():\n",
    "    \"\"\"Preprocessing pipeline built around HAAR feature based cascade classifiers. \"\"\"\n",
    "    \n",
    "    def __init__(self, face_size):\n",
    "        self.face_size = face_size\n",
    "        self.modelFile = \"./models/opencv_face_detector.caffemodel\"\n",
    "        self.configFile = \"./models/deploy.prototxt.txt\"\n",
    "        self.net = cv2.dnn.readNetFromCaffe(self.configFile, self.modelFile)\n",
    "        self.default_confidence = 0.5\n",
    "    \n",
    "            \n",
    "    def detect_faces(self, img):\n",
    "        \"\"\"Detect all faces in an image.\"\"\"\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1.0,(300, 300), (104.0, 117.0, 123.0))\n",
    "        self.net.setInput(blob)\n",
    "        return self.net.forward()\n",
    "        \n",
    "    def extract_faces(self, img):\n",
    "        \"\"\"Returns all faces (cropped) in an image.\"\"\"\n",
    "        confidence = self.default_confidence\n",
    "        faces = []\n",
    "        h, w = img.shape[:2]\n",
    "        f = self.detect_faces(img)\n",
    "        #to draw faces on image\n",
    "        for i in range(f.shape[2]):\n",
    "                c = f[0, 0, i, 2]\n",
    "                if c > confidence and confidence == 0.5:\n",
    "                    faces.append((f[0, 0, i, 3:7] * np.array([w, h, w, h])).astype(\"int\"))\n",
    "                    confidence = c\n",
    "                elif c > confidence and confidence != 0.5:\n",
    "                    faces.pop()\n",
    "                    faces.append((f[0, 0, i, 3:7] * np.array([w, h, w, h])).astype(\"int\"))\n",
    "                    confidence = c\n",
    "                    \n",
    "        return [img[y:y1, x:x1]  for (x, y, x1, y1) in faces]\n",
    "    \n",
    "    def preprocess(self, data_row):\n",
    "        faces = self.extract_faces(data_row['img'])\n",
    "        \n",
    "        # if no faces were found, return None\n",
    "        if len(faces) == 0:\n",
    "            nan_img = np.empty(self.face_size + (3,))\n",
    "            nan_img[:] = np.nan\n",
    "            return nan_img\n",
    "        # only return the first face\n",
    "        return cv2.resize(faces[0], self.face_size, interpolation = cv2.INTER_AREA)\n",
    "            \n",
    "    def __call__(self, data):\n",
    "        return np.stack([self.preprocess(row) for _, row in data.iterrows()]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025332,
     "end_time": "2021-03-08T07:57:50.885849",
     "exception": false,
     "start_time": "2021-03-08T07:57:50.860517",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Visualise**\n",
    "\n",
    "Let's plot a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 62.263517,
     "end_time": "2021-03-08T07:58:53.174859",
     "exception": false,
     "start_time": "2021-03-08T07:57:50.911342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parameter to play with \n",
    "FACE_SIZE = (224, 224)\n",
    "\n",
    "def plot_image_sequence(data, n, imgs_per_row=7):\n",
    "    n_rows = 1 + int(n/(imgs_per_row+1))\n",
    "    n_cols = min(imgs_per_row, n)\n",
    "\n",
    "    f,ax = plt.subplots(n_rows,n_cols, figsize=(10*n_cols,10*n_rows))\n",
    "    for i in range(n):\n",
    "        if n == 1:\n",
    "            ax.imshow(data[i].astype('uint8'))\n",
    "        elif n_rows > 1:\n",
    "            ax[int(i/imgs_per_row),int(i%imgs_per_row)].imshow(data[i].astype('uint8'))\n",
    "        else:\n",
    "            ax[int(i%n)].imshow(data[i].astype('uint8'))\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "#preprocessed data \n",
    "preprocessor = DNNPreprocessor(face_size=FACE_SIZE)\n",
    "\n",
    "train_modified = copy.deepcopy(train)\n",
    "\n",
    "# #train_set preprocessing to improve the performance of the face_detector.\n",
    "# #Double face in a single image are removed. \n",
    "train_img = train_modified['img'].values\n",
    "train_img[5] = train_img[5][0:400, :]\n",
    "train_img[70] = train_img[70][:, 150:]\n",
    "train_img[61] = train_img[61][:, 100:]\n",
    "train_img[60] = train_img[60][0:1500,:]\n",
    "train_img[59] = train_img[59][:, 200:]\n",
    "train_img[53] = train_img[53][:, 250:]\n",
    "train_img[52] = train_img[52][:, 300:]\n",
    "train_img[50] = train_img[50][0:300,:]\n",
    "train_img[49] = train_img[49][:, 0:150]\n",
    "train_img[41] = train_img[41][:, 0:200]\n",
    "train_img[39] = train_img[39][:, 125:225]\n",
    "train_img[40] = train_img[40][:, 100:]\n",
    "train_img[34] = train_img[34][:, 200:400]\n",
    "train_img[29] = train_img[29][:, :400]\n",
    "train_img[28] = train_img[28][:, 0:500]\n",
    "train_img[18] = train_img[18][:, :250]\n",
    "\n",
    "train_X, train_y = preprocessor(train_modified), train['class'].values\n",
    "\n",
    "#Image65 is wrong (total black), so it is eliminated\n",
    "train_X = np.delete(train_X, 65, axis=0)\n",
    "train_y = np.delete(train_y, 65, axis=0)\n",
    "\n",
    "test_X = preprocessor(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 2.635787,
     "end_time": "2021-03-08T07:58:55.836611",
     "exception": false,
     "start_time": "2021-03-08T07:58:53.200824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot faces of Michael and Sarah\n",
    "\n",
    "plot_image_sequence(train_X[train_y == 0], n=train_X[train_y == 0].shape[0], imgs_per_row=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 3.840961,
     "end_time": "2021-03-08T07:58:59.72249",
     "exception": false,
     "start_time": "2021-03-08T07:58:55.881529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot faces of Jesse\n",
    "\n",
    "plot_image_sequence(train_X[train_y == 1], n=train_X[train_y == 1].shape[0], imgs_per_row=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 3.910256,
     "end_time": "2021-03-08T07:59:03.703299",
     "exception": false,
     "start_time": "2021-03-08T07:58:59.793043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot faces of Mila\n",
    "\n",
    "plot_image_sequence(train_X[train_y == 2], n=train_X[train_y == 2].shape[0], imgs_per_row=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.100995,
     "end_time": "2021-03-08T07:59:03.904684",
     "exception": false,
     "start_time": "2021-03-08T07:59:03.803689",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "## 0.4. Store Preprocessed data (optional)\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>NOTE:</b> You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\". Feel free to use this to store intermediary results.\n",
    "</div>\n",
    "\n",
    "Data after data augmentation can be stored using the code in this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.109823,
     "end_time": "2021-03-08T07:59:04.11528",
     "exception": false,
     "start_time": "2021-03-08T07:59:04.005457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prep_path = './kaggle/working/prepped_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save preprocessed data\n",
    "# np.save(os.path.join(prep_path, 'train_X.npy'), train_X)\n",
    "# np.save(os.path.join(prep_path, 'train_y.npy'), train_y)\n",
    "# np.save(os.path.join(prep_path, 'test_X.npy'), test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load preprocessed data\n",
    "# train_X = np.load(os.path.join(prep_path, 'train_X.npy'))\n",
    "# train_y = np.load(os.path.join(prep_path, 'train_y.npy'))\n",
    "# test_X = np.load(os.path.join(prep_path, 'test_X.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.5 Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation: image flip\n",
    "\n",
    "The plot below explains the flip operation. This occurs when the probability is between 0 and 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_X[9]]\n",
    "data.append(cv2.flip(train_X[9], 1))\n",
    "\n",
    "plot_image_sequence(data, 2, imgs_per_row=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation: image rotation\n",
    "\n",
    "The plot below shows the rotation operation. This occurs when the probability is between 0.3 and 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Compose(\n",
    "             [tr.RandomRotation(degrees = 90),\n",
    "              tr.RandomRotation(degrees = 270)])\n",
    "\n",
    "image = train_X[9]\n",
    "image = Image.fromarray(np.uint8(image)).convert('RGB')\n",
    "augmented_image = pipeline(img = image)\n",
    "\n",
    "data = [image, augmented_image]\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(image)\n",
    "plt.imshow(augmented_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation: final operation\n",
    "\n",
    "The given code snippet below augments the given data, with the flip and rotation operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "pipeline = Compose(\n",
    "             [tr.RandomRotation(degrees = 90),\n",
    "              tr.RandomRotation(degrees = 270)])\n",
    "\n",
    "# augmented_image = pipeline(img = img)\n",
    "\n",
    "print(len(train_X))\n",
    "augm_train_X = []\n",
    "augm_train_y = []\n",
    "\n",
    "threshold = 0.3\n",
    "\n",
    "for idx, im in enumerate(train_X):\n",
    "    augm_train_X.append(im)\n",
    "    augm_train_y.append(train_y[idx])\n",
    "    \n",
    "    rand = random.uniform(0, 1)\n",
    "    \n",
    "    if rand < threshold:\n",
    "        flipped = cv2.flip(im, 1)\n",
    "        augm_train_X.append(flipped)\n",
    "        augm_train_y.append(train_y[idx])\n",
    "    elif rand > threshold and rand < (threshold * 2):\n",
    "        image = Image.fromarray(np.uint8(im)).convert('RGB')\n",
    "        augmented_image = pipeline(img = image)\n",
    "        augm_train_X.append(np.array(image))\n",
    "        augm_train_y.append(train_y[idx])\n",
    "\n",
    "print(len(augm_train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(augm_train_X)\n",
    "train_y = np.array(augm_train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.100101,
     "end_time": "2021-03-08T07:59:04.315571",
     "exception": false,
     "start_time": "2021-03-08T07:59:04.21547",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we are ready to rock!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG Classifier (WIP)\n",
    "\n",
    "Load the weights of VGG16 and freeze them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "#from tensorflow.keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model, load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.applications import vgg16\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD, Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class DeepNNClassificationModel:\n",
    "    \n",
    "    def __init__(self):\n",
    "        # MobileNet was designed to work on 224 x 224 pixel input images sizes\n",
    "        self.img_rows, self.img_cols = 224, 224 \n",
    "\n",
    "        # Re-loads the MobileNet model without the top or FC layers\n",
    "        vgg = vgg16.VGG16(weights = 'imagenet', \n",
    "                         include_top = False, \n",
    "                         input_shape = (self.img_rows, self.img_cols, 3))\n",
    "\n",
    "        # Here we freeze the vgg layers\n",
    "        # Layers are set to trainable as True by default\n",
    "        for layer in vgg.layers:\n",
    "            layer.trainable = False\n",
    "        \n",
    "        num_classes = 3\n",
    "\n",
    "        FC_Head = self.lw(vgg, num_classes)\n",
    "\n",
    "        self.model = Model(inputs = vgg.input, outputs = FC_Head)\n",
    "\n",
    "    def lw(self, bottom_model, num_classes):\n",
    "        \"\"\"creates the top or head of the model that will be \n",
    "        placed ontop of the bottom layers\"\"\"\n",
    "\n",
    "        top_model = bottom_model.output\n",
    "        top_model = GlobalAveragePooling2D()(top_model)\n",
    "        top_model = Dense(1024,activation='relu')(top_model)\n",
    "        top_model = Dense(1024,activation='relu')(top_model)\n",
    "        top_model = Dense(512,activation='relu')(top_model)\n",
    "        top_model = Dense(num_classes,activation='softmax')(top_model)\n",
    "        return top_model \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        X_train = np.zeros((X.shape[0],self.img_rows,self.img_cols,3))\n",
    "        i=0\n",
    "        for x in X:\n",
    "            x = x.astype(dtype=\"uint8\")\n",
    "            X_train[i] = cv2.resize(x, (self.img_rows,self.img_cols),interpolation = cv2.INTER_AREA)\n",
    "            X_train[i] = cv2.GaussianBlur(X_train[i], (5,5), 0)\n",
    "            i+=1\n",
    "        \n",
    "        train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.3, stratify = y, random_state=42)\n",
    "        \n",
    "        train_y=to_categorical(train_y) # convert Y into an one-hot vector\n",
    "        val_y=to_categorical(val_y) # convert Y into an one-hot vector\n",
    "        \n",
    "        # Let's use some data augmentation \n",
    "        train_datagen = ImageDataGenerator(\n",
    "              rescale=1./255,\n",
    "#               rotation_range=45,\n",
    "#               width_shift_range=0.3,\n",
    "#               height_shift_range=0.3,\n",
    "#               horizontal_flip=True,\n",
    "#               fill_mode='nearest'\n",
    "        )\n",
    "        \n",
    "        validation_datagen = ImageDataGenerator(\n",
    "              rescale=1./255\n",
    "        )\n",
    "        \n",
    "        # We use a very small learning rate \n",
    "        # 'categorical_crossentropy'\n",
    "        self.model.compile(loss = 'kl_divergence',\n",
    "                      optimizer = Adam(learning_rate=0.0001),\n",
    "                      metrics = ['accuracy'])\n",
    "        \n",
    "        # set our batch size (typically on most mid tier systems we'll use 16-32)\n",
    "        batch_size = 16\n",
    "        nb_train_samples = 32\n",
    "        nb_validation_samples = 16\n",
    "        epochs = 100\n",
    "        \n",
    "        train_generator = train_datagen.flow(\n",
    "                train_X, train_y,\n",
    "                batch_size=16)\n",
    "        \n",
    "        validation_generator = validation_datagen.flow(\n",
    "                val_X, val_y,\n",
    "                batch_size = 16)\n",
    "        \n",
    "        checkpoint = ModelCheckpoint(\"face_recognisation.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "        earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                                  min_delta = 0, \n",
    "                                  patience = 20,\n",
    "                                  verbose = 1,\n",
    "                                  restore_best_weights = True)\n",
    "\n",
    "        # we put our call backs into a callback list\n",
    "        callbacks = [earlystop, checkpoint]\n",
    "\n",
    "        history = self.model.fit(\n",
    "            train_generator,\n",
    "            batch_size=batch_size,\n",
    "            steps_per_epoch = nb_train_samples // batch_size,\n",
    "            epochs = epochs,\n",
    "            callbacks = callbacks,\n",
    "            validation_data = validation_generator,\n",
    "            validation_steps = nb_validation_samples // batch_size)\n",
    "        \n",
    "        return history\n",
    "        \n",
    "    def predict(self, X):\n",
    "        classifier = load_model('face_recognisation.h5')\n",
    "        y=[]\n",
    "        for input_im in X:\n",
    "            input_im = input_im.astype(dtype=\"uint8\")\n",
    "            input_im = cv2.resize(input_im, (self.img_rows, self.img_cols), interpolation = cv2.INTER_LINEAR)\n",
    "            input_im = input_im / 255.\n",
    "            input_im = input_im.reshape(1,self.img_rows,self.img_cols,3) \n",
    "            \n",
    "            res = np.argmax(classifier.predict(input_im, verbose = 0), axis=1)\n",
    "            y.append(res)\n",
    "            \n",
    "        return np.array(y, dtype=\"int\")\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        return self.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1402 - accuracy: 0.4062\n",
      "Epoch 1: val_loss improved from inf to 1.10531, saving model to face_recognisation.h5\n",
      "2/2 [==============================] - 4s 2s/step - loss: 1.1402 - accuracy: 0.4062 - val_loss: 1.1053 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0177 - accuracy: 0.5312\n",
      "Epoch 2: val_loss did not improve from 1.10531\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.0177 - accuracy: 0.5312 - val_loss: 1.1682 - val_accuracy: 0.2500\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9983 - accuracy: 0.4400\n",
      "Epoch 3: val_loss improved from 1.10531 to 1.04268, saving model to face_recognisation.h5\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.9983 - accuracy: 0.4400 - val_loss: 1.0427 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0143 - accuracy: 0.4688\n",
      "Epoch 4: val_loss improved from 1.04268 to 0.95209, saving model to face_recognisation.h5\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.0143 - accuracy: 0.4688 - val_loss: 0.9521 - val_accuracy: 0.6875\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9850 - accuracy: 0.6562\n",
      "Epoch 5: val_loss did not improve from 0.95209\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.9850 - accuracy: 0.6562 - val_loss: 0.9640 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9514 - accuracy: 0.4062\n",
      "Epoch 6: val_loss did not improve from 0.95209\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.9514 - accuracy: 0.4062 - val_loss: 1.0235 - val_accuracy: 0.4375\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9800 - accuracy: 0.4375\n",
      "Epoch 7: val_loss did not improve from 0.95209\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.9800 - accuracy: 0.4375 - val_loss: 0.9612 - val_accuracy: 0.5625\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8640 - accuracy: 0.7600\n",
      "Epoch 8: val_loss improved from 0.95209 to 0.91634, saving model to face_recognisation.h5\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.8640 - accuracy: 0.7600 - val_loss: 0.9163 - val_accuracy: 0.6875\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7970 - accuracy: 0.8800\n",
      "Epoch 9: val_loss improved from 0.91634 to 0.82414, saving model to face_recognisation.h5\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.7970 - accuracy: 0.8800 - val_loss: 0.8241 - val_accuracy: 0.7500\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7980 - accuracy: 0.7188\n",
      "Epoch 10: val_loss did not improve from 0.82414\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.7980 - accuracy: 0.7188 - val_loss: 0.8831 - val_accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8846 - accuracy: 0.6000\n",
      "Epoch 11: val_loss did not improve from 0.82414\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.8846 - accuracy: 0.6000 - val_loss: 0.9263 - val_accuracy: 0.4375\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8332 - accuracy: 0.6800\n",
      "Epoch 12: val_loss improved from 0.82414 to 0.80118, saving model to face_recognisation.h5\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.8332 - accuracy: 0.6800 - val_loss: 0.8012 - val_accuracy: 0.6875\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7427 - accuracy: 0.8125\n",
      "Epoch 13: val_loss improved from 0.80118 to 0.73675, saving model to face_recognisation.h5\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.7427 - accuracy: 0.8125 - val_loss: 0.7367 - val_accuracy: 0.7500\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7370 - accuracy: 0.7500\n",
      "Epoch 14: val_loss did not improve from 0.73675\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.7370 - accuracy: 0.7500 - val_loss: 0.9360 - val_accuracy: 0.6250\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7781 - accuracy: 0.6800\n",
      "Epoch 15: val_loss did not improve from 0.73675\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.7781 - accuracy: 0.6800 - val_loss: 0.8912 - val_accuracy: 0.6250\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7939 - accuracy: 0.6875\n",
      "Epoch 16: val_loss did not improve from 0.73675\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.7939 - accuracy: 0.6875 - val_loss: 0.9790 - val_accuracy: 0.6250\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6809 - accuracy: 0.7500\n",
      "Epoch 17: val_loss improved from 0.73675 to 0.70026, saving model to face_recognisation.h5\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.6809 - accuracy: 0.7500 - val_loss: 0.7003 - val_accuracy: 0.9375\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7241 - accuracy: 0.8438\n",
      "Epoch 18: val_loss did not improve from 0.70026\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.7241 - accuracy: 0.8438 - val_loss: 0.7034 - val_accuracy: 0.8750\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6478 - accuracy: 0.8438\n",
      "Epoch 19: val_loss did not improve from 0.70026\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.6478 - accuracy: 0.8438 - val_loss: 0.7697 - val_accuracy: 0.6250\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6802 - accuracy: 0.7500\n",
      "Epoch 20: val_loss did not improve from 0.70026\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.6802 - accuracy: 0.7500 - val_loss: 0.8707 - val_accuracy: 0.5625\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6352 - accuracy: 0.7500\n",
      "Epoch 21: val_loss improved from 0.70026 to 0.67473, saving model to face_recognisation.h5\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.6352 - accuracy: 0.7500 - val_loss: 0.6747 - val_accuracy: 0.7500\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5734 - accuracy: 0.7812\n",
      "Epoch 22: val_loss did not improve from 0.67473\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.5734 - accuracy: 0.7812 - val_loss: 0.9290 - val_accuracy: 0.5625\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5597 - accuracy: 0.7812\n",
      "Epoch 23: val_loss did not improve from 0.67473\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.5597 - accuracy: 0.7812 - val_loss: 0.7797 - val_accuracy: 0.5625\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4141 - accuracy: 0.9200\n",
      "Epoch 24: val_loss did not improve from 0.67473\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.4141 - accuracy: 0.9200 - val_loss: 0.7694 - val_accuracy: 0.6250\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4750 - accuracy: 0.8400\n",
      "Epoch 25: val_loss did not improve from 0.67473\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.4750 - accuracy: 0.8400 - val_loss: 0.7362 - val_accuracy: 0.6250\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6553 - accuracy: 0.6875\n",
      "Epoch 26: val_loss did not improve from 0.67473\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.6553 - accuracy: 0.6875 - val_loss: 0.8175 - val_accuracy: 0.6250\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5692 - accuracy: 0.7600\n",
      "Epoch 27: val_loss did not improve from 0.67473\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.5692 - accuracy: 0.7600 - val_loss: 0.7875 - val_accuracy: 0.6250\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3274 - accuracy: 0.9600\n",
      "Epoch 28: val_loss did not improve from 0.67473\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.3274 - accuracy: 0.9600 - val_loss: 0.8918 - val_accuracy: 0.6875\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5040 - accuracy: 0.8400\n",
      "Epoch 29: val_loss did not improve from 0.67473\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.5040 - accuracy: 0.8400 - val_loss: 0.7860 - val_accuracy: 0.6875\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.5936 - accuracy: 0.6875\n",
      "Epoch 30: val_loss did not improve from 0.67473\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.5936 - accuracy: 0.6875 - val_loss: 0.7439 - val_accuracy: 0.7500\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5007 - accuracy: 0.8438\n",
      "Epoch 31: val_loss did not improve from 0.67473\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.5007 - accuracy: 0.8438 - val_loss: 0.7189 - val_accuracy: 0.8125\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4326 - accuracy: 0.9062\n",
      "Epoch 32: val_loss did not improve from 0.67473\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.4326 - accuracy: 0.9062 - val_loss: 0.8215 - val_accuracy: 0.6250\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5277 - accuracy: 0.7812\n",
      "Epoch 33: val_loss did not improve from 0.67473\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.5277 - accuracy: 0.7812 - val_loss: 0.7908 - val_accuracy: 0.6250\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4569 - accuracy: 0.7812\n",
      "Epoch 34: val_loss did not improve from 0.67473\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.4569 - accuracy: 0.7812 - val_loss: 0.7358 - val_accuracy: 0.5625\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5381 - accuracy: 0.8438\n",
      "Epoch 35: val_loss did not improve from 0.67473\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.5381 - accuracy: 0.8438 - val_loss: 0.8198 - val_accuracy: 0.6250\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4070 - accuracy: 0.8750\n",
      "Epoch 36: val_loss improved from 0.67473 to 0.56177, saving model to face_recognisation.h5\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.4070 - accuracy: 0.8750 - val_loss: 0.5618 - val_accuracy: 0.8750\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5223 - accuracy: 0.7200\n",
      "Epoch 37: val_loss did not improve from 0.56177\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.5223 - accuracy: 0.7200 - val_loss: 0.7542 - val_accuracy: 0.7500\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4388 - accuracy: 0.8000\n",
      "Epoch 38: val_loss did not improve from 0.56177\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.4388 - accuracy: 0.8000 - val_loss: 0.6758 - val_accuracy: 0.6875\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4408 - accuracy: 0.8400\n",
      "Epoch 39: val_loss did not improve from 0.56177\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.4408 - accuracy: 0.8400 - val_loss: 0.5856 - val_accuracy: 0.7500\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4076 - accuracy: 0.8125\n",
      "Epoch 40: val_loss did not improve from 0.56177\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.4076 - accuracy: 0.8125 - val_loss: 0.9269 - val_accuracy: 0.6875\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3762 - accuracy: 0.9200\n",
      "Epoch 41: val_loss did not improve from 0.56177\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.3762 - accuracy: 0.9200 - val_loss: 0.6768 - val_accuracy: 0.7500\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4057 - accuracy: 0.8438\n",
      "Epoch 42: val_loss did not improve from 0.56177\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.4057 - accuracy: 0.8438 - val_loss: 0.8370 - val_accuracy: 0.6250\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5007 - accuracy: 0.7600\n",
      "Epoch 43: val_loss did not improve from 0.56177\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.5007 - accuracy: 0.7600 - val_loss: 0.7995 - val_accuracy: 0.6875\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3552 - accuracy: 0.9200\n",
      "Epoch 44: val_loss did not improve from 0.56177\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.3552 - accuracy: 0.9200 - val_loss: 0.5939 - val_accuracy: 0.6875\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4452 - accuracy: 0.8000\n",
      "Epoch 45: val_loss did not improve from 0.56177\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.4452 - accuracy: 0.8000 - val_loss: 1.0749 - val_accuracy: 0.6250\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4412 - accuracy: 0.8750\n",
      "Epoch 46: val_loss did not improve from 0.56177\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.4412 - accuracy: 0.8750 - val_loss: 0.5626 - val_accuracy: 0.6875\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4007 - accuracy: 0.8438\n",
      "Epoch 47: val_loss did not improve from 0.56177\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.4007 - accuracy: 0.8438 - val_loss: 0.7162 - val_accuracy: 0.6250\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2229 - accuracy: 0.9600\n",
      "Epoch 48: val_loss improved from 0.56177 to 0.48840, saving model to face_recognisation.h5\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.2229 - accuracy: 0.9600 - val_loss: 0.4884 - val_accuracy: 0.8750\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4012 - accuracy: 0.8400\n",
      "Epoch 49: val_loss did not improve from 0.48840\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.4012 - accuracy: 0.8400 - val_loss: 0.6334 - val_accuracy: 0.6875\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2179 - accuracy: 0.9200\n",
      "Epoch 50: val_loss did not improve from 0.48840\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.2179 - accuracy: 0.9200 - val_loss: 0.7370 - val_accuracy: 0.6250\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3176 - accuracy: 0.9600\n",
      "Epoch 51: val_loss did not improve from 0.48840\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.3176 - accuracy: 0.9600 - val_loss: 0.7225 - val_accuracy: 0.6875\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4381 - accuracy: 0.7812\n",
      "Epoch 52: val_loss did not improve from 0.48840\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.4381 - accuracy: 0.7812 - val_loss: 0.5364 - val_accuracy: 0.7500\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4279 - accuracy: 0.8400\n",
      "Epoch 53: val_loss did not improve from 0.48840\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.4279 - accuracy: 0.8400 - val_loss: 0.6434 - val_accuracy: 0.7500\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3486 - accuracy: 0.8800\n",
      "Epoch 54: val_loss did not improve from 0.48840\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.3486 - accuracy: 0.8800 - val_loss: 0.6654 - val_accuracy: 0.7500\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3839 - accuracy: 0.8800\n",
      "Epoch 55: val_loss did not improve from 0.48840\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.3839 - accuracy: 0.8800 - val_loss: 0.6243 - val_accuracy: 0.7500\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3406 - accuracy: 0.9375\n",
      "Epoch 56: val_loss did not improve from 0.48840\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.3406 - accuracy: 0.9375 - val_loss: 0.5661 - val_accuracy: 0.8750\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2632 - accuracy: 0.9688\n",
      "Epoch 57: val_loss did not improve from 0.48840\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.2632 - accuracy: 0.9688 - val_loss: 0.6524 - val_accuracy: 0.7500\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3477 - accuracy: 0.9200\n",
      "Epoch 58: val_loss did not improve from 0.48840\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.3477 - accuracy: 0.9200 - val_loss: 0.6761 - val_accuracy: 0.7500\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3266 - accuracy: 0.9062\n",
      "Epoch 59: val_loss did not improve from 0.48840\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.3266 - accuracy: 0.9062 - val_loss: 0.6043 - val_accuracy: 0.7500\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.4376 - accuracy: 0.8125\n",
      "Epoch 60: val_loss did not improve from 0.48840\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.4376 - accuracy: 0.8125 - val_loss: 0.8095 - val_accuracy: 0.7500\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3226 - accuracy: 0.8800\n",
      "Epoch 61: val_loss did not improve from 0.48840\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.3226 - accuracy: 0.8800 - val_loss: 0.8165 - val_accuracy: 0.6875\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3692 - accuracy: 0.7200\n",
      "Epoch 62: val_loss did not improve from 0.48840\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.3692 - accuracy: 0.7200 - val_loss: 0.6936 - val_accuracy: 0.6875\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2973 - accuracy: 0.9062\n",
      "Epoch 63: val_loss did not improve from 0.48840\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.2973 - accuracy: 0.9062 - val_loss: 0.7576 - val_accuracy: 0.8125\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2825 - accuracy: 0.9600\n",
      "Epoch 64: val_loss did not improve from 0.48840\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.2825 - accuracy: 0.9600 - val_loss: 0.7457 - val_accuracy: 0.8750\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3796 - accuracy: 0.8800\n",
      "Epoch 65: val_loss did not improve from 0.48840\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.3796 - accuracy: 0.8800 - val_loss: 0.6732 - val_accuracy: 0.7500\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3621 - accuracy: 0.8750\n",
      "Epoch 66: val_loss did not improve from 0.48840\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.3621 - accuracy: 0.8750 - val_loss: 0.9845 - val_accuracy: 0.6250\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2514 - accuracy: 0.9688\n",
      "Epoch 67: val_loss did not improve from 0.48840\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.2514 - accuracy: 0.9688 - val_loss: 0.6074 - val_accuracy: 0.6875\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2823 - accuracy: 0.9062Restoring model weights from the end of the best epoch: 48.\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.48840\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.2823 - accuracy: 0.9062 - val_loss: 0.9961 - val_accuracy: 0.5000\n",
      "Epoch 68: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = DeepNNClassificationModel()\n",
    "\n",
    "history = model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"Loss\",\"Val Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests = []\n",
    "\n",
    "# for input_im in test['img']:\n",
    "#     input_im = input_im.astype(dtype=\"uint8\")\n",
    "#     input_im = cv2.resize(input_im, (224, 224), interpolation = cv2.INTER_LINEAR)\n",
    "# #     input_im = input_im / 255.\n",
    "# #     input_im = input_im.reshape(1,224,224,3) \n",
    "#     tests.append(input_im)\n",
    "\n",
    "# tests = np.array(tests)\n",
    "\n",
    "results = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"submission.csv\")\n",
    "submission['class'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.100212,
     "end_time": "2021-03-08T07:59:04.516059",
     "exception": false,
     "start_time": "2021-03-08T07:59:04.415847",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Feature Representations\n",
    "## 1.0. Example: Identify feature extractor\n",
    "Our example feature extractor doesn't actually do anything... It just returns the input:\n",
    "$$\n",
    "\\forall x : f(x) = x.\n",
    "$$\n",
    "\n",
    "It does make for a good placeholder and baseclass ;)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.108781,
     "end_time": "2021-03-08T07:59:04.725071",
     "exception": false,
     "start_time": "2021-03-08T07:59:04.61629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IdentityFeatureExtractor:\n",
    "    \"\"\"A simple function that returns the input\"\"\"\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.134288,
     "end_time": "2021-03-08T07:59:04.959911",
     "exception": false,
     "start_time": "2021-03-08T07:59:04.825623",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.1. Baseline 1: HOG feature extractor/Scale Invariant Feature Transform\n",
    "Possible improvements:\n",
    "- grid search to study the best parameterz on a validation set\n",
    "- preprocessing (normalization, ecc.)\n",
    "\n",
    "For HOG/SIFT explanation link on the assignment pdf.\n",
    "\n",
    "HOG performances with default parameters : 0.84581 (with GaussianBlur)\n",
    "SIFT performances with default parameters : 0.69913"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.110122,
     "end_time": "2021-03-08T07:59:05.171171",
     "exception": false,
     "start_time": "2021-03-08T07:59:05.061049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HOGFeatureExtractor(IdentityFeatureExtractor):\n",
    "    \n",
    "    def __init__(self, blockSize = (40,40), blockStride = (20,20), cellSize = (20,20), nbins = 18, derivAperture = 1\n",
    ", winSigma = -1, histogramNormType = 0, L2HysThreshold = 0.2, gammaCorrection = 1, nlevels = 64, signedGradients = True):\n",
    "        self.blockSize = blockSize\n",
    "        self.blockStride = blockStride\n",
    "        self.cellSize = cellSize\n",
    "        self.nbins = nbins\n",
    "        self.derivAperture = derivAperture\n",
    "        self.winSigma = winSigma\n",
    "        self.histogramNormType = histogramNormType \n",
    "        self.L2HysThreshold = L2HysThreshold\n",
    "        self.gammaCorrection = gammaCorrection\n",
    "        self.nlevels = nlevels\n",
    "        self.signedGradients = signedGradients         \n",
    "        \n",
    "    def transform(self, X):\n",
    "        X = X.astype(np.uint8)\n",
    "        hog = cv2.HOGDescriptor((X.shape[1], X.shape[2]), self.blockSize, self.blockStride, self.cellSize, self.nbins,\n",
    "                                self.derivAperture, self.winSigma, self.histogramNormType,self.L2HysThreshold,\n",
    "                                self.gammaCorrection, self.nlevels, self.signedGradients)\n",
    "        descriptors = []\n",
    "        resultimage = np.zeros((FACE_SIZE[0], FACE_SIZE[1]))\n",
    "\n",
    "        for x in X:\n",
    "            img = cv2.GaussianBlur(x, (5,5), 0)\n",
    "            descriptors.append(hog.compute(img))\n",
    "\n",
    "        descriptors = np.array(descriptors)\n",
    "        descriptors = np.resize(descriptors, (descriptors.shape[0], descriptors.shape[1]))\n",
    "        return descriptors   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIFTFeatureExtractor(IdentityFeatureExtractor):\n",
    "    \n",
    "    def __init__(self, nfeatures=200, nOctaveLayers=3, contrastThreshold=0.04, edgeThreshold=10, sigma=1.6, n_clusters = 200):\n",
    "        self.nfeatures = nfeatures\n",
    "        self.nOctaveLayers = nOctaveLayers\n",
    "        self.contrastThreshold = contrastThreshold\n",
    "        self.edgeThreshold = edgeThreshold \n",
    "        self.sigma = sigma\n",
    "        self.flag = 1 # 1 for train set, 0 for test \n",
    "        self.n_clusters = n_clusters\n",
    "        self.bow = []\n",
    "    \n",
    "    def extract_sift_features(self, list_image):\n",
    "\n",
    "        image_descriptors = []\n",
    "        sift = cv2.SIFT_create()\n",
    "        for image in list_image:        \n",
    "            _, descriptor = sift.detectAndCompute(image, None)\n",
    "            image_descriptors.append(descriptor)\n",
    "\n",
    "        return image_descriptors\n",
    "\n",
    "    def kmean_bow(self, all_descriptors, n_clusters):\n",
    "        bow_dict = []\n",
    "\n",
    "        kmeans = KMeans(n_clusters = n_clusters)\n",
    "        kmeans.fit(all_descriptors)\n",
    "\n",
    "        bow_dict = kmeans.cluster_centers_\n",
    "        self.bow = bow_dict\n",
    "        \n",
    "        return bow_dict\n",
    "\n",
    "    def create_feature_bow(self, image_descriptors, BoW, n_clusters):\n",
    "\n",
    "        X_features = []\n",
    "\n",
    "        for i in range(len(image_descriptors)):\n",
    "            features = np.zeros(n_clusters)\n",
    "\n",
    "            if image_descriptors[i] is not None:\n",
    "                distance = cdist(image_descriptors[i], BoW)\n",
    "\n",
    "                argmin = np.argmin(distance, axis = 1)\n",
    "\n",
    "                for j in argmin:\n",
    "                    features[j] += 1\n",
    "            X_features.append(features)\n",
    "\n",
    "        return X_features\n",
    "\n",
    "        \n",
    "    def transform(self, X):  \n",
    "        \n",
    "        X = X.astype(np.uint8)\n",
    "        \n",
    "        image_descriptors = self.extract_sift_features(X)\n",
    "        \n",
    "        # train mode\n",
    "        if self.flag == 1: \n",
    "            all_descriptors = []\n",
    "            for descriptor in image_descriptors:\n",
    "                if descriptor is not None:\n",
    "                    for des in descriptor:\n",
    "                        all_descriptors.append(des)\n",
    "\n",
    "            BoW = self.kmean_bow(all_descriptors, self.n_clusters)\n",
    "            \n",
    "            self.flag = 0 #switch to test mode\n",
    "            \n",
    "            return self.create_feature_bow(image_descriptors, BoW, self.n_clusters)\n",
    "        \n",
    "        # test mode\n",
    "        elif self.flag == 0:\n",
    "            return self.create_feature_bow(image_descriptors, self.bow, self.n_clusters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.100377,
     "end_time": "2021-03-08T07:59:05.372401",
     "exception": false,
     "start_time": "2021-03-08T07:59:05.272024",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.1.1. t-SNE Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.100308,
     "end_time": "2021-03-08T07:59:05.57403",
     "exception": false,
     "start_time": "2021-03-08T07:59:05.473722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "\n",
    "hog = HOGFeatureExtractor()\n",
    "\n",
    "X_embedded = TSNE().fit_transform(hog.transform(train_X))\n",
    "\n",
    "plt.ylim([-200, 200])\n",
    "plt.xlim([-200,200])\n",
    "sns.scatterplot(x=X_embedded[:,0], y=X_embedded[:,1], hue=train_y, legend='full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.100596,
     "end_time": "2021-03-08T07:59:05.775686",
     "exception": false,
     "start_time": "2021-03-08T07:59:05.67509",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.1.2. Discussion\n",
    "Class 1 and 2 are well separated. Difficult discrimination between class 0-1 and 0-2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.101426,
     "end_time": "2021-03-08T07:59:05.978236",
     "exception": false,
     "start_time": "2021-03-08T07:59:05.87681",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.2. Baseline 2: PCA feature extractor\n",
    "\n",
    "Number of features can be determined by n_components (which depends on the number of images in the training data) or the percentage of variance to be retained.\n",
    "\n",
    "Not many parameters can be improved.\n",
    "\n",
    "PCA performances with default parameters : 0.77843"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.111032,
     "end_time": "2021-03-08T07:59:06.191215",
     "exception": false,
     "start_time": "2021-03-08T07:59:06.080183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PCAFeatureExtractor(IdentityFeatureExtractor):\n",
    "    \n",
    "    def __init__(self, train_X, n_components = None, var = 0.95):\n",
    "        train_X = train_X.astype(np.uint8)\n",
    "        gray_train_X = []\n",
    "        \n",
    "        #code to ensure grayscale conversion\n",
    "        if len(train_X) > 3 and train_X.shape[3] > 1:\n",
    "            for x in train_X:\n",
    "                gray_train_X.append(cv2.cvtColor(x, cv2.COLOR_BGR2GRAY))\n",
    "                \n",
    "        gray_train_X = np.array(gray_train_X)\n",
    "        \n",
    "        self.n_components = n_components\n",
    "        self.variance = var\n",
    "        #mean image computation\n",
    "        mean_image = gray_train_X.mean(axis=0)\n",
    "        #centered_data computation\n",
    "        centered_train = gray_train_X - mean_image\n",
    "        \n",
    "        m = train_X.shape[0]\n",
    "        d = FACE_SIZE[0] * FACE_SIZE[1]\n",
    "        images_matrix = np.reshape(centered_train, (m, d))\n",
    "        if n_components == None:\n",
    "            self.pca = PCA(n_components=var, svd_solver=\"full\", whiten=True).fit(images_matrix)\n",
    "        else:\n",
    "            self.pca = PCA(n_components=n_components, svd_solver=\"randomized\", whiten=True).fit(images_matrix)\n",
    "            \n",
    "        \n",
    "    def transform(self, X):\n",
    "        X = X.astype(np.uint8)        \n",
    "        gray_X = []\n",
    "        \n",
    "        #code to ensure grayscale conversion\n",
    "        if len(X.shape) == 4:\n",
    "            m = X.shape[0]\n",
    "            if X.shape[3] > 1:\n",
    "                for x in X:\n",
    "                    gray_X.append(cv2.cvtColor(x, cv2.COLOR_BGR2GRAY))\n",
    "            else:\n",
    "                gray_X = np.array(X)\n",
    "            \n",
    "            gray_X = np.array(gray_X)\n",
    "        else:\n",
    "            if len(X.shape) > 2 and X.shape[2] > 1:\n",
    "                 gray_X = cv2.cvtColor(X, cv2.COLOR_BGR2GRAY)\n",
    "            m = 1\n",
    "        d = FACE_SIZE[0] * FACE_SIZE[1]\n",
    "        gray_X = np.reshape(gray_X, (m, d))\n",
    "        return self.pca.transform(gray_X)\n",
    "        \n",
    "    def inverse_transform(self, X):\n",
    "        data = self.pca.inverse_transform(X)\n",
    "        n_images = int(data.size / (FACE_SIZE[0]*FACE_SIZE[1]))\n",
    "        \n",
    "        data = np.array(data, dtype=np.uint8)\n",
    "        \n",
    "        if n_images > 1:\n",
    "            return np.reshape(data, (n_images, FACE_SIZE[0], FACE_SIZE[1]))\n",
    "        return np.reshape(data, (FACE_SIZE[0], FACE_SIZE[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.100881,
     "end_time": "2021-03-08T07:59:06.392861",
     "exception": false,
     "start_time": "2021-03-08T07:59:06.29198",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.2.1. Eigenface Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = train_X[9]\n",
    "\n",
    "max_eigenvectors = train_X.shape[0]\n",
    "\n",
    "used_eigenvalues = np.linspace(10, max_eigenvectors, int(max_eigenvectors/10), dtype=int)[::-1]\n",
    "\n",
    "eigenfaces_images = np.zeros((int(max_eigenvectors/10), FACE_SIZE[0], FACE_SIZE[1], 3))\n",
    "\n",
    "for components in used_eigenvalues:\n",
    "    pca = PCAFeatureExtractor(train_X, components)\n",
    "    reduced_data = pca.transform(image)\n",
    "    reconstructed_data = pca.inverse_transform(reduced_data)\n",
    "    idx = int((max_eigenvectors - components) / 10)\n",
    "    eigenfaces_images[idx] = cv2.cvtColor(reconstructed_data, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "plot_image_sequence(eigenfaces_images, n=eigenfaces_images.shape[0], imgs_per_row=10)  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.101263,
     "end_time": "2021-03-08T07:59:06.797448",
     "exception": false,
     "start_time": "2021-03-08T07:59:06.696185",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.2.2. Feature Space Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.101801,
     "end_time": "2021-03-08T07:59:07.000598",
     "exception": false,
     "start_time": "2021-03-08T07:59:06.898797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca = PCAFeatureExtractor(train_X, 2)\n",
    "\n",
    "reduced_data = pca.transform(train_X)\n",
    "\n",
    "plt.plot(reduced_data[:,0][train_y == 0], reduced_data[:,1][train_y == 0], 'o', label=\"False\")\n",
    "plt.plot(reduced_data[:,0][train_y == 1], reduced_data[:,1][train_y == 1], 'o', label=\"Jesse Eisemberg\")\n",
    "plt.plot(reduced_data[:,0][train_y == 2], reduced_data[:,1][train_y == 2], 'o', label=\"Mila Kunis\")\n",
    "plt.title(\"Projecting the images in the 2D eigenspace\")\n",
    "plt.legend()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.102099,
     "end_time": "2021-03-08T07:59:07.204783",
     "exception": false,
     "start_time": "2021-03-08T07:59:07.102684",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.2.3. Discussion\n",
    "\n",
    "Again class 1 and 2 are well separated, while discrimination is difficult between class 0-1 and 0-2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.10088,
     "end_time": "2021-03-08T07:59:07.406787",
     "exception": false,
     "start_time": "2021-03-08T07:59:07.305907",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Evaluation Metrics\n",
    "## 2.0. Example: Accuracy\n",
    "As example metric we take the accuracy. Informally, accuracy is the proportion of correct predictions over the total amount of predictions. It is used a lot in classification but it certainly has its disadvantages..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.180116,
     "end_time": "2021-03-08T07:59:08.688561",
     "exception": false,
     "start_time": "2021-03-08T07:59:07.508445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.103749,
     "end_time": "2021-03-08T07:59:08.894358",
     "exception": false,
     "start_time": "2021-03-08T07:59:08.790609",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Classifiers\n",
    "## 3.0. Example: The *'not so smart'* classifier\n",
    "This random classifier is not very complicated. It makes predictions at random, based on the distribution obseved in the training set. **It thus assumes** that the class labels of the test set will be distributed similarly to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.113194,
     "end_time": "2021-03-08T07:59:09.110222",
     "exception": false,
     "start_time": "2021-03-08T07:59:08.997028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RandomClassificationModel:\n",
    "    \"\"\"Random classifier, draws a random sample based on class distribution observed \n",
    "    during training.\"\"\"\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Adjusts the class ratio instance variable to the one observed in y. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : tensor\n",
    "            Training set\n",
    "        y : array\n",
    "            Training set labels\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : RandomClassificationModel\n",
    "        \"\"\" \n",
    "        \n",
    "        self.classes, self.class_ratio = np.unique(y, return_counts=True)\n",
    "        self.class_ratio = self.class_ratio / self.class_ratio.sum()\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"Samples labels for the input data. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : tensor\n",
    "            dataset\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        y_star : array\n",
    "            'Predicted' labels\n",
    "        \"\"\"\n",
    "\n",
    "        np.random.seed(0)\n",
    "        return np.random.choice(self.classes, size = X.shape[0], p=self.class_ratio)\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        return self.predict(X)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Baseline 1: SVM classifier\n",
    "Two binary classifiers (usually work better for SVM).\n",
    "\n",
    "Randomized search for the estimation of the best hyperparameters.\n",
    "\n",
    "RBF kernel to obtain non-linear decision boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVMClassificationModel:\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        #Jesse classifier\n",
    "        Y_jesse = np.array(y)\n",
    "        Y_jesse[Y_jesse == 2] = 0\n",
    "        \n",
    "        param_grid = {\n",
    "            \"C\": loguniform(1e3, 1e5),\n",
    "            \"gamma\": loguniform(1e-4, 1e-1),\n",
    "        }\n",
    "        clf_jesse = RandomizedSearchCV(\n",
    "            SVC(kernel=\"rbf\", class_weight=\"balanced\", random_state=9), param_grid, n_iter=1000, cv=20, random_state=9\n",
    "        )\n",
    "        clf_jesse = clf_jesse.fit(X, Y_jesse)\n",
    "        self.C_jesse = clf_jesse.best_estimator_.C\n",
    "        self.gamma_jesse = clf_jesse.best_estimator_.gamma\n",
    "        self.clf_jesse = clf_jesse\n",
    "        \n",
    "        #Mila classifier\n",
    "        Y_mila = np.array(y)\n",
    "        Y_mila[Y_mila == 1] = 0\n",
    "        \n",
    "        clf_mila = RandomizedSearchCV(\n",
    "            SVC(kernel=\"rbf\", class_weight=\"balanced\", random_state=9), param_grid, n_iter=1000, cv=10, random_state=9\n",
    "        )\n",
    "        clf_mila = clf_mila.fit(X, Y_mila)\n",
    "        self.C_mila = clf_mila.best_estimator_.C\n",
    "        self.gamma_mila = clf_mila.best_estimator_.gamma\n",
    "        self.clf_mila = clf_mila\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \n",
    "        y_jesse = self.clf_jesse.predict(X)\n",
    "        y_mila = self.clf_mila.predict(X)\n",
    "        \n",
    "        y = np.zeros(y_jesse.size, dtype=int)\n",
    "        \n",
    "        y[np.logical_and(y_jesse == 1, y_mila == 0)] = 1\n",
    "        y[np.logical_and(y_jesse == 0, y_mila == 2)] = 2\n",
    "        \n",
    "        #random choice when both Mila and Jesse are predicted\n",
    "        y[np.logical_and(y_jesse == 1, y_mila == 2)] = np.random.randint(0,2)\n",
    "        for i in range(y.size):\n",
    "            if y_jesse[i] == 1 and y_mila[i] == 2:\n",
    "                print(\"ERROR: both Jesse and Mila labels are predicted\")\n",
    "                \n",
    "        y_with_four_labels = np.array(y, dtype=int)\n",
    "        y_with_four_labels[np.logical_and(y_jesse == 1, y_mila == 2)] = 3\n",
    "        \n",
    "        return y, y_with_four_labels\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        return self.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.101099,
     "end_time": "2021-03-08T07:59:09.31402",
     "exception": false,
     "start_time": "2021-03-08T07:59:09.212921",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3.2. Baseline 2: Voting among SVM classifiers\n",
    "\n",
    "Voting among the three classifiers that use HOG, SIFT and PCA features.\n",
    "\n",
    "Surprisingly, it does not work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.108542,
     "end_time": "2021-03-08T07:59:09.525054",
     "exception": false,
     "start_time": "2021-03-08T07:59:09.416512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VotingClassificationModel:\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        hog_features = X[0]\n",
    "        sift_features = X[1]\n",
    "        pca_features = X[2]\n",
    "        \n",
    "        self.hog_classifier = SVMClassificationModel()\n",
    "        self.hog_classifier.fit(hog_features, y)\n",
    "        \n",
    "        self.sift_classifier = SVMClassificationModel()\n",
    "        self.sift_classifier.fit(sift_features, y)\n",
    "        \n",
    "        self.pca_classifier = SVMClassificationModel()\n",
    "        self.pca_classifier.fit(pca_features, y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        hog_features = X[0]\n",
    "        sift_features = X[1]\n",
    "        pca_features = X[2]\n",
    "        y_hog, y_four_hog = self.hog_classifier.predict(hog_features)\n",
    "        y_sift, y_four_sift = y_mila_sift = self.sift_classifier.predict(sift_features)\n",
    "        y_pca, y_four_pca = self.pca_classifier.predict(pca_features)\n",
    "        \n",
    "        self.c0 = self.c1 = self.c2 = self.c3 = self.c4 = 0\n",
    "        y_final = -1*np.zeros((y_hog.size), dtype=int)\n",
    "        \n",
    "        for i in range(y_hog.size):\n",
    "            values = np.array([y_four_hog[i], y_four_sift[i], y_four_pca[i]])\n",
    "            \n",
    "            n_zeros = np.where(values == 0, 1, 0).sum()\n",
    "            n_ones = np.where(values == 1, 1, 0).sum()\n",
    "            n_twos = np.where(values == 2, 1, 0).sum()\n",
    "            n_threes = np.where(values == 3, 1, 0).sum()\n",
    "            \n",
    "            if n_zeros >= 2:\n",
    "                y_final[i] = 0\n",
    "            elif n_ones >= 2:\n",
    "                y_final[i] = 1\n",
    "            elif n_twos >= 2:\n",
    "                y_final[i] = 2\n",
    "            elif n_threes >= 2:\n",
    "                self.c0 += 1\n",
    "                y_final[i] = y_hog[i]\n",
    "            elif n_ones == 1 and n_twos == 1 and n_zeros == 1:\n",
    "                self.c1 += 1\n",
    "                y_final[i] = y_hog[i]\n",
    "            elif n_ones == 1 and n_zeros == 1 and n_threes == 1:\n",
    "                self.c2 += 1\n",
    "                y_final[i] = y_hog[i]\n",
    "            elif n_zeros == 1 and n_twos == 1 and n_threes == 1:\n",
    "                self.c3 += 1\n",
    "                y_final[i] = y_hog[i]\n",
    "            elif n_ones == 1 and n_twos == 1 and n_threes == 1:\n",
    "                self.c4 += 1\n",
    "                y_final[i] = y_hog[i]\n",
    "                \n",
    "        return y_final\n",
    "    def __call__(self, X):\n",
    "        y = self.predict(X)\n",
    "        print(self.c0)\n",
    "        print(self.c1)\n",
    "        print(self.c2)\n",
    "        print(self.c3)\n",
    "        print(self.c4)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Baseline: My favorite classifer\n",
    "Up to now, the best performing classifier is the SVM with HOG features.\n",
    "\n",
    "A possible improvement can be the VGG ImageNet with Data Augmentation. As you can read on https://arxiv.org/pdf/1804.06655.pdf, this NN approach should be the best performing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.102942,
     "end_time": "2021-03-08T07:59:09.730342",
     "exception": false,
     "start_time": "2021-03-08T07:59:09.6274",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Experiments\n",
    "<div class=\"alert alert-block alert-info\"> <b>NOTE:</b> Do <i>NOT</i> use this section to keep track of every little change you make in your code! Instead, highlight the most important findings and the major (best) pipelines that you've discovered.  \n",
    "</div>\n",
    "<br>\n",
    "\n",
    "## 4.0. Example: basic pipeline\n",
    "The basic pipeline takes any input and samples a label based on the class label distribution of the training set. As expected the performance is very poor, predicting approximately 1/4 correctly on the training set. There is a lot of room for improvement but this is left to you ;). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.430319,
     "end_time": "2021-03-08T07:59:10.263691",
     "exception": false,
     "start_time": "2021-03-08T07:59:09.833372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_extractor = IdentityFeatureExtractor() \n",
    "classifier = RandomClassificationModel()\n",
    "\n",
    "# train the model on the features\n",
    "classifier.fit(feature_extractor(train_X), train_y)\n",
    "\n",
    "# model/final pipeline\n",
    "model = lambda X: classifier(feature_extractor(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.114717,
     "end_time": "2021-03-08T07:59:10.480473",
     "exception": false,
     "start_time": "2021-03-08T07:59:10.365756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evaluate performance of the model on the training set\n",
    "train_y_star = model(train_X)\n",
    "\n",
    "\"The performance on the training set is {:.2f}. This however, does not tell us much about the actual performance (generalisability).\".format(\n",
    "    accuracy_score(train_y, train_y_star))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.111828,
     "end_time": "2021-03-08T07:59:10.696438",
     "exception": false,
     "start_time": "2021-03-08T07:59:10.58461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predict the labels for the test set \n",
    "test_y_star = model(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. SVM model: basic pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1. SVM model: HOGFeatureDescriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = HOGFeatureExtractor() \n",
    "classifier_hog = SVMClassificationModel()\n",
    "\n",
    "# train the model on the features\n",
    "classifier_hog.fit(feature_extractor(train_X), train_y)\n",
    "\n",
    "# model/final pipeline\n",
    "model_hog = lambda X: classifier_hog(feature_extractor(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance of the model on the training set\n",
    "train_y_hog, _ = model_hog(train_X)\n",
    "\n",
    "\"The performance on the training set is {:.2f}. This however, does not tell us much about the actual performance (generalisability).\".format(\n",
    "    accuracy_score(train_y, train_y_hog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the labels for the test set \n",
    "test_y_hog, _ = model_hog(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2. SVM model: SIFTFeatureDescriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = SIFTFeatureExtractor() \n",
    "classifier_sift = SVMClassificationModel()\n",
    "\n",
    "# train the model on the features\n",
    "classifier_sift.fit(feature_extractor(train_X), train_y)\n",
    "\n",
    "# model/final pipeline\n",
    "model_sift = lambda X: classifier_sift(feature_extractor(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance of the model on the training set\n",
    "train_y_sift, _ = model_sift(train_X)\n",
    "\n",
    "\"The performance on the training set is {:.2f}. This however, does not tell us much about the actual performance (generalisability).\".format(\n",
    "    accuracy_score(train_y, train_y_sift))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the labels for the test set \n",
    "test_y_sift, _ = model_sift(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3. SVM model: PCAFeatureDescriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = PCAFeatureExtractor(train_X) \n",
    "classifier_pca = SVMClassificationModel()\n",
    "\n",
    "# train the model on the features\n",
    "classifier_pca.fit(feature_extractor(train_X), train_y)\n",
    "\n",
    "# model/final pipeline\n",
    "model_pca = lambda X: classifier_pca(feature_extractor(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### evaluate performance of the model on the training set\n",
    "train_y_pca, _ = model_pca(train_X)\n",
    "\n",
    "\"The performance on the training set is {:.2f}. This however, does not tell us much about the actual performance (generalisability).\".format(\n",
    "    accuracy_score(train_y, train_y_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the labels for the test set \n",
    "test_y_pca, _ = model_pca(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Voting model: voting among SVM classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_hog = HOGFeatureExtractor() \n",
    "feature_extractor_sift = SIFTFeatureExtractor() \n",
    "feature_extractor_pca = PCAFeatureExtractor(train_X) \n",
    "\n",
    "classifier = VotingClassificationModel()\n",
    "\n",
    "# train the model on the features\n",
    "classifier.fit([feature_extractor_hog(train_X), feature_extractor_sift(train_X), feature_extractor_pca(train_X)], train_y)\n",
    "\n",
    "# model/final pipeline\n",
    "model = lambda X: classifier([feature_extractor_hog(X), feature_extractor_sift(X), feature_extractor_pca(X)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the labels for the test set \n",
    "test_y = model(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.103853,
     "end_time": "2021-03-08T07:59:10.903341",
     "exception": false,
     "start_time": "2021-03-08T07:59:10.799488",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Publishing best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.120392,
     "end_time": "2021-03-08T07:59:11.127762",
     "exception": false,
     "start_time": "2021-03-08T07:59:11.00737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = test.copy().drop('img', axis = 1)\n",
    "submission['class'] = test_y_hog\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.122516,
     "end_time": "2021-03-08T07:59:11.356409",
     "exception": false,
     "start_time": "2021-03-08T07:59:11.233893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.116655,
     "end_time": "2021-03-08T07:59:11.577703",
     "exception": false,
     "start_time": "2021-03-08T07:59:11.461048",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6. Discussion\n",
    "...\n",
    "\n",
    "In summary we contributed the following: \n",
    "* \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
